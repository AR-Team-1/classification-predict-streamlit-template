{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Classification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**Caleb, Tanko**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: Climate Change Tweet Classification Challenge\n",
    "\n",
    "<!-- The government of Spain is considering an expansion of it's renewable energy resource infrastructure investments. As such, they require information on the trends and patterns of the countries renewable sources and fossil fuel energy generation. Your company has been awarded the contract to:\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement was given to you, the senior data scientist, by your manager via email reads as follow:\n",
    "\n",
    "> In this project you are tasked to model the shortfall between the energy generated by means of fossil fuels and various renewable sources - for the country of Spain. The daily shortfall, which will be referred to as the target variable, will be modelled as a function of various city-specific weather features such as `pressure`, `wind speed`, `humidity`, etc. As with all data science projects, the provided features are rarely adequate predictors of the target variable. As such, you are required to perform feature engineering to ensure that you will be able to accurately model Spain's three hourly shortfalls.\n",
    " \n",
    "On top of this, she has provided you with a starter notebook containing vague explanations of what the main outcomes are.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "#PARAMETER_CONSTANT = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loaded train data into df_train DataFrame\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009cb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded test data into df_test DataFrame\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117b6cf",
   "metadata": {},
   "source": [
    "### Examine the Dataframe by calling the head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the head function to display the FIVE top records of the data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5228b9ad",
   "metadata": {},
   "source": [
    "##### From the above cell, we can observe we have the sentiment (Label) ,  message and tweetid as features\n",
    "\n",
    "Variable definitions\n",
    "- sentiment: Sentiment of tweet\n",
    "- message: Tweet body\n",
    "- tweetid: Twitter unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb74182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are null values in our data\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa7060",
   "metadata": {},
   "source": [
    "##### From the above Cell there are no null values in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd6ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, -1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_types = list(df_train['sentiment'].unique())\n",
    "sentiment_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f0908",
   "metadata": {},
   "source": [
    "##### from the above cell, we can identify four different sentiments;\n",
    "* 2 News: the tweet links to factual news about climate change\n",
    "* 1 Pro: the tweet supports the belief of man-made climate change\n",
    "* 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "* -1 Anti: the tweet does not believe in man-made climate change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddd6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data is 15819\n"
     ]
    }
   ],
   "source": [
    "# Length of the dataset\n",
    "print('length of data is', len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deecf9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the Shape of data\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488b52e",
   "metadata": {},
   "source": [
    "### Data  Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ae2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data Information\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca342270",
   "metadata": {},
   "source": [
    "#### Checking the datatypes of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8827781e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     int64\n",
       "message      object\n",
       "tweetid       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types of all columns\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8310de",
   "metadata": {},
   "source": [
    "### Let's have a look at how many data samples we have for each different sentiment types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5dcc295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the value_counts() method to get the number of samples in each sentiment\n",
    "df_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0f8656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['sentiment'].value_counts().plot(kind = 'bar', title= 'Distribution of Sentiment', xlabel='Sentiment', ylabel='Number of Samples')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864955b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5f65caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='sentiment', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22524f",
   "metadata": {},
   "source": [
    "#### From the above graph, we can conclude on the following;\n",
    "* The sentiment types are not evenly distributed in our data.\n",
    "* Pro(1) have over 8000 data samples represented as the highest\n",
    "* Anti(-1) has the lowest data samples represented with a little above  1000 samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50eed81",
   "metadata": {},
   "source": [
    "### Summary from EDA\n",
    " From the above exploratory Data Analysis, we observed the following;\n",
    " \n",
    "   1. The data has three features(tweetid, message and sentiment)\n",
    "   \n",
    "   2. The data doesn't contain NULL values.\n",
    "   \n",
    "   3. The data contains four Unique sentiment types;\n",
    "     * 2 News: the tweet links to factual news about climate change\n",
    "     * 1 Pro: the tweet supports the belief of man-made climate change\n",
    "     * 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "     * -1 Anti: the tweet does not believe in man-made climate change\n",
    "     \n",
    "   4. The total length of data is 15819.\n",
    "   \n",
    "   5. The tweetid and sentiment columns are numeric data types.\n",
    "   \n",
    "   6. The message column is an object data type.\n",
    "   \n",
    "   7. The data samples accross the sentiment types are inbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Preprocessing\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data Preprocessing ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section the data would be sujected to different text preprocessing approach to aid better perfomance on our model. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the message and sentiment column for our further analysis\n",
    "data = df_train[['message','sentiment']]\n",
    "\n",
    "# select the message column in our test data\n",
    "test_data = df_test['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee88e1",
   "metadata": {},
   "source": [
    "### Converting text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84eea17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief doesn't think carbon di...\n",
       "1    it's not like we lack evidence of anthropogeni...\n",
       "2    rt @rawstory: researchers say we have three ye...\n",
       "3    #todayinmaker# wired : 2016 was a pivotal year...\n",
       "4    rt @soynoviodetodas: it's 2016, and a racist, ...\n",
       "5    worth a read whether you do or don't believe i...\n",
       "6    rt @thenation: mike pence doesn’t believe in g...\n",
       "7    rt @makeandmendlife: six big things we can all...\n",
       "8    @aceofspadeshq my 8yo nephew is inconsolable. ...\n",
       "9    rt @paigetweedy: no offense… but like… how do ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making message text into lower case for train data\n",
    "data['message'] = data['message'].str.lower()\n",
    "\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb47519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making message text into lower case for test data\n",
    "test_data = test_data.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef30ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "def remove_emoji(data):\n",
    "    tweet = ''.join(c for c in data if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1009104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief doesn't think carbon di...\n",
       "1    it's not like we lack evidence of anthropogeni...\n",
       "2    rt @rawstory: researchers say we have three ye...\n",
       "3    #todayinmaker# wired : 2016 was a pivotal year...\n",
       "4    rt @soynoviodetodas: it's 2016, and a racist, ...\n",
       "5    worth a read whether you do or don't believe i...\n",
       "6    rt @thenation: mike pence doesn’t believe in g...\n",
       "7    rt @makeandmendlife: six big things we can all...\n",
       "8    @aceofspadeshq my 8yo nephew is inconsolable. ...\n",
       "9    rt @paigetweedy: no offense… but like… how do ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using lambda function to apply the above function to the message column in our train data\n",
    "data['message'] = data['message'].apply(lambda message: remove_emoji(message))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befb003",
   "metadata": {},
   "source": [
    "###  Removing all Stop Words in Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cca6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the variable to store all stopwords\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fac662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72afd5",
   "metadata": {},
   "source": [
    "##### removing the above stop words list from the tweet message with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d510845",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords_list)\n",
    "\n",
    "# developed a function that removes stopwords from a text\n",
    "def cleaning_stopwords(message):\n",
    "    '''this function takes a in a message as input,\n",
    "        uses list comprehension to generate a list \n",
    "        of words in input without stopwords, \n",
    "        the it is later joined together\n",
    "    '''\n",
    "    return \" \".join([word for word in str(message).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a856ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2    rt @rawstory: researchers say three years act ...\n",
       "3    #todayinmaker# wired : 2016 pivotal year war c...\n",
       "4    rt @soynoviodetodas: 2016, racist, sexist, cli...\n",
       "5    worth read whether believe climate change http...\n",
       "6    rt @thenation: mike pence doesn’t believe glob...\n",
       "7    rt @makeandmendlife: six big things today figh...\n",
       "8    @aceofspadeshq 8yo nephew inconsolable. wants ...\n",
       "9    rt @paigetweedy: offense… like… believe… globa...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using lambda function to apply the above function to the message column in our train data\n",
    "data['message'] = data['message'].apply(lambda message: cleaning_stopwords(message))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d20c03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lambda function to apply the above function to the message column in our test data\n",
    "test_data = test_data.apply(lambda message: cleaning_stopwords(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf66012",
   "metadata": {},
   "source": [
    "### Removing Punctuations from Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f4233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the string library to import all available punctuations and declaring a variable to store all the punctuations\n",
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80b8d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that removes punctuations for a given text\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78047d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2    rt rawstory researchers say three years act cl...\n",
       "3    todayinmaker wired  2016 pivotal year war clim...\n",
       "4    rt soynoviodetodas 2016 racist sexist climate ...\n",
       "5    worth read whether believe climate change http...\n",
       "6    rt thenation mike pence doesn’t believe global...\n",
       "7    rt makeandmendlife six big things today fight ...\n",
       "8    aceofspadeshq 8yo nephew inconsolable wants di...\n",
       "9    rt paigetweedy offense… like… believe… global ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our train data\n",
    "data['message']= data['message'].apply(lambda x: cleaning_punctuations(x))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92a5ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our test_data\n",
    "test_data= test_data.apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff7f90",
   "metadata": {},
   "source": [
    "### Removing redundant characters in Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e27448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that removes repeating characters in a given text\n",
    "def cleaning_redundant_char(text):\n",
    "    cleaned = re.sub(r'(.)1+', r'1', text)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f82180e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2    rt rawstory researchers say three years act cl...\n",
       "3    todayinmaker wired  216 pivotal year war clima...\n",
       "4    rt soynoviodetodas 216 racist sexist climate c...\n",
       "5    worth read whether believe climate change http...\n",
       "6    rt thenation mike pence doesn’t believe global...\n",
       "7    rt makeandmendlife six big things today fight ...\n",
       "8    aceofspadeshq 8yo nephew inconsolable wants di...\n",
       "9    rt paigetweedy offense… like… believe… global ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our train data\n",
    "\n",
    "data['message'] = data['message'].apply(lambda x: cleaning_redundant_char(x))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09858301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our test_data\n",
    "\n",
    "test_data = test_data.apply(lambda x: cleaning_redundant_char(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d6205",
   "metadata": {},
   "source": [
    "### Removing URLs from Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3b28e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that removes all URLs in a given text\n",
    "\n",
    "def removing_URLs(data):\n",
    "    cleaned = re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db6185ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2    rt rawstory researchers say three years act cl...\n",
       "3    todayinmaker wired  216 pivotal year war clima...\n",
       "4    rt soynoviodetodas 216 racist sexist climate c...\n",
       "5    worth read whether believe climate change http...\n",
       "6    rt thenation mike pence doesn’t believe global...\n",
       "7    rt makeandmendlife six big things today fight ...\n",
       "8    aceofspadeshq 8yo nephew inconsolable wants di...\n",
       "9    rt paigetweedy offense… like… believe… global ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our train data\n",
    "\n",
    "data['message'] = data['message'].apply(lambda x: removing_URLs(x))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede3355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our test_data\n",
    "\n",
    "test_data = test_data.apply(lambda x: removing_URLs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a6cfb",
   "metadata": {},
   "source": [
    "### Removing Numbers from Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13af2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Function that removes numbers from a given text of data\n",
    "def removing_numbers(data):\n",
    "    cleaned = re.sub('[0-9]+', '', data)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82a40124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2    rt rawstory researchers say three years act cl...\n",
       "3    todayinmaker wired   pivotal year war climate ...\n",
       "4    rt soynoviodetodas  racist sexist climate chan...\n",
       "5    worth read whether believe climate change http...\n",
       "6    rt thenation mike pence doesn’t believe global...\n",
       "7    rt makeandmendlife six big things today fight ...\n",
       "8    aceofspadeshq yo nephew inconsolable wants die...\n",
       "9    rt paigetweedy offense… like… believe… global ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our train data\n",
    "\n",
    "data['message'] = data['message'].apply(lambda x: removing_numbers(x))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85e1e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our test_data\n",
    "\n",
    "test_data = test_data.apply(lambda x: removing_numbers(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e052522",
   "metadata": {},
   "source": [
    "### Removing 'rt' from Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c51c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that removes 'rt' from a given text data\n",
    "def removing_rt(data):\n",
    "    cleaned = re.sub('rt', '', data)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff38da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2     rawstory researchers say three years act clim...\n",
       "3    todayinmaker wired   pivotal year war climate ...\n",
       "4     soynoviodetodas  racist sexist climate change...\n",
       "5    woh read whether believe climate change httpst...\n",
       "6     thenation mike pence doesn’t believe global w...\n",
       "7     makeandmendlife six big things today fight cl...\n",
       "8    aceofspadeshq yo nephew inconsolable wants die...\n",
       "9     paigetweedy offense… like… believe… global wa...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our train data\n",
    "\n",
    "data['message'] = data['message'].apply(lambda x: removing_rt(x))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f5f0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our test_data\n",
    "\n",
    "test_data = test_data.apply(lambda x: removing_rt(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8c67443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags(data):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, removes all words started with '#' and '@' in the column,\n",
    "        and returns a new dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern_tags = r'#\\w+[#?]'\n",
    "    pattern_2 = r'@\\w+'\n",
    "    pattern_3 = r'[0-9]+'\n",
    "    pattern_4 = r'[^\\x00-\\x7f]' # Pattern for unicode\n",
    "    subs_tag = ''\n",
    "    data = data.replace(to_replace = pattern_tags, value = subs_tag, regex = True)\n",
    "    data = data.replace(to_replace = pattern_2, value = subs_tag, regex = True)\n",
    "    data = data.replace(to_replace = pattern_3, value = subs_tag, regex = True)\n",
    "    data = data.replace(to_replace = pattern_4, value = subs_tag, regex = True) # Where it is being removed\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e741c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2     rawstory researchers say three years act clim...\n",
       "3    todayinmaker wired   pivotal year war climate ...\n",
       "4     soynoviodetodas  racist sexist climate change...\n",
       "5    woh read whether believe climate change httpst...\n",
       "6     thenation mike pence doesnt believe global wa...\n",
       "7     makeandmendlife six big things today fight cl...\n",
       "8    aceofspadeshq yo nephew inconsolable wants die...\n",
       "9      paigetweedy offense like believe global warming\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['message'] = delete_tags(data['message'])\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdc447c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = delete_tags(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fd0d8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    polyscimajor epa chief think carbon dioxide ma...\n",
       "1      like lack evidence anthropogenic global warming\n",
       "2    rawstory researchers say three years act clima...\n",
       "3    todayinmaker wired pivotal year war climate ch...\n",
       "4    soynoviodetodas racist sexist climate change d...\n",
       "5    woh read whether believe climate change httpst...\n",
       "6    thenation mike pence doesnt believe global war...\n",
       "7    makeandmendlife six big things today fight cli...\n",
       "8    aceofspadeshq yo nephew inconsolable wants die...\n",
       "9      paigetweedy offense like believe global warming\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using lambda function to apply the above function to the message column in our train data\n",
    "data['message'] = data['message'].apply(lambda message: cleaning_stopwords(message))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bd7e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seperate_words(data):\n",
    "    \n",
    "\n",
    "# #separate the words\n",
    "#     tweet = \" \".join([s for s in re.split(\"([A-Z][a-z]+[^A-Z]*)\",data)])\n",
    "#     return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f18c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using lambda function to apply the above function to the message column in our train data\n",
    "# data['message'] = seperate_words(data['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f686a",
   "metadata": {},
   "source": [
    "### Tokenization of Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "185c61e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, think, carbon, diox...\n",
       "1    [like, lack, evidence, anthropogenic, global, ...\n",
       "2    [rawstory, researchers, say, three, years, act...\n",
       "3    [todayinmaker, wired, pivotal, year, war, clim...\n",
       "4    [soynoviodetodas, racist, sexist, climate, cha...\n",
       "5    [woh, read, whether, believe, climate, change,...\n",
       "6    [thenation, mike, pence, doesnt, believe, glob...\n",
       "7    [makeandmendlife, six, big, things, today, fig...\n",
       "8    [aceofspadeshq, yo, nephew, inconsolable, want...\n",
       "9    [paigetweedy, offense, like, believe, global, ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization of the tweet message column of our train data\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "data['message'] = data['message'].apply(tokeniser.tokenize)\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40cc867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of the tweet message column of our test data\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "test_data = test_data.apply(tokeniser.tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765d939",
   "metadata": {},
   "source": [
    "### Lemmatization of Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a3f18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Lemmatizer on our data\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lm = WordNetLemmatizer() # instantiate the lemmatizer object\n",
    "\n",
    "# A function that appllies Lemmatization on a given text data\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e067680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, think, carbon, diox...\n",
       "1    [like, lack, evidence, anthropogenic, global, ...\n",
       "2    [rawstory, researcher, say, three, year, act, ...\n",
       "3    [todayinmaker, wired, pivotal, year, war, clim...\n",
       "4    [soynoviodetodas, racist, sexist, climate, cha...\n",
       "5    [woh, read, whether, believe, climate, change,...\n",
       "6    [thenation, mike, penny, doesnt, believe, glob...\n",
       "7    [makeandmendlife, six, big, thing, today, figh...\n",
       "8    [aceofspadeshq, yo, nephew, inconsolable, want...\n",
       "9    [paigetweedy, offense, like, believe, global, ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our train data\n",
    "\n",
    "data['message'] = data['message'].apply(lambda x: lemmatizer_on_text(x))\n",
    "data['message'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f467e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used a lambda function to apply the above  function to the message column in our test_data\n",
    "\n",
    "test_data = test_data.apply(lambda x: lemmatizer_on_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289bc76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea7a860",
   "metadata": {},
   "source": [
    "### Resampling of Data\n",
    " \n",
    " Recall from our Exploratory Data Analysis, we observed that the distribution of sentiment in the data is imbalanced.\n",
    " Hence the need for Resampling.\n",
    " SKlearn would be used to achieve this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffeac15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#divide data into dataframe of majority and minority class with 4000 as the benchmark\n",
    "df_majority = data[(data['sentiment']==1)] # majority as it has a value greater than benchmark\n",
    "df_minority1 = data[(data['sentiment']==2)] # minority as it has a value lesser than benchmark\n",
    "df_minority2 = data[(data['sentiment']==0)] # minority as it has a value lesser than benchmark\n",
    "df_minority3 = data[(data['sentiment']==-1)] # minority as it has a value lesser than benchmark\n",
    "\n",
    "# upsample minority class\n",
    "df_minority_upsampled1 = resample(df_minority1, \n",
    "                                 replace=True,    # sample with replacement\n",
    "                                 n_samples= 8530, # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "df_minority_upsampled2 = resample(df_minority2, \n",
    "                                 replace=True,    # sample with replacement\n",
    "                                 n_samples= 8530, # to match majority class\n",
    "                                 random_state=42) \n",
    "\n",
    "df_minority_upsampled3 = resample(df_minority3, \n",
    "                                 replace=True,    # sample with replacement\n",
    "                                 n_samples= 8530, # to match majority class\n",
    "                                 random_state=42) \n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority classes using pd.concat\n",
    "data_upsampled = pd.concat([df_minority_upsampled1, df_minority_upsampled2, df_minority_upsampled3, df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ddc415d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    8530\n",
       " 1    8530\n",
       " 2    8530\n",
       "-1    8530\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the value_counts of sentiments values\n",
    "data_upsampled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959dd5c",
   "metadata": {},
   "source": [
    "##### * from the above we can see that our sentiment distribution is now balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41eeb0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data is 34120\n"
     ]
    }
   ],
   "source": [
    "# Length of the dataset\n",
    "print('length of data is', len(data_upsampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a12bc",
   "metadata": {},
   "source": [
    "* from the above cell, we observe a significant increase in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, different models were trained and used to predict classes of our test data |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the train data into X and y\n",
    "X = data_upsampled.message\n",
    "y = data_upsampled.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364f5b9",
   "metadata": {},
   "source": [
    "#### Splitting our data into Train and Test Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2b0d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the train_test_split model of sklearn to split our data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717eb8db",
   "metadata": {},
   "source": [
    "#### Transforming data using TF-IDF VEctorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "426c817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the TF-IDF vectorizer object to a variable tt\n",
    "tt = TfidfVectorizer(preprocessor=list, tokenizer=list, ngram_range=(1,2),min_df=2, strip_accents = 'ascii', smooth_idf=False)\n",
    "\n",
    "# A function that vectorise a given text of data input\n",
    "def vectorise(X_train, X_test, test_data):\n",
    "    '''\n",
    "    This function takes in three input, two from our train data and one from the test data,\n",
    "    fits and transforms the data.\n",
    "    The function returns an output of the vectorised inputs\n",
    "    '''\n",
    "    tt.fit(X_train)\n",
    "    X_train = tt.transform(X_train)\n",
    "    X_test = tt.transform(X_test)\n",
    "    test_data = tt.transform(test_data)\n",
    "    \n",
    "    return X_train, X_test, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c34c02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the vectorise funtion on X_train, X_test, test_data\n",
    "X_train, X_test, test_data = vectorise(X_train, X_test, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794a0f2",
   "metadata": {},
   "source": [
    "#### Funtion to Evalute models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f381e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a funtion that evaluates the model based on classifcation report of SKlearn\n",
    "def model_Evaluate(model):\n",
    "    '''\n",
    "    This functions the input of a model name, \n",
    "    get the predictions for X_test,\n",
    "    and evaluates the perfomance of the model with the classification report\n",
    "    '''\n",
    "    y_pred = model.predict(X_test) # get predict values for Test dataset\n",
    "\n",
    "    return print(classification_report(y_test, y_pred)) # Print the evaluation metrics for the dataset.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06196e",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86f04aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.96      0.96      1671\n",
      "           0       0.95      0.84      0.89      1722\n",
      "           1       0.75      0.90      0.82      1724\n",
      "           2       0.93      0.85      0.89      1707\n",
      "\n",
      "    accuracy                           0.89      6824\n",
      "   macro avg       0.90      0.89      0.89      6824\n",
      "weighted avg       0.90      0.89      0.89      6824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiating the model, training the model, calling the evaluation functon on the model and getting predictions from the model\n",
    "BNBmodel = BernoulliNB()\n",
    "BNBmodel.fit(X_train, y_train) \n",
    "model_Evaluate(BNBmodel) \n",
    "y_pred = BNBmodel.predict(X_test)\n",
    "#y_pred1 = BNBmodel.predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b718aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f8a8b",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e90e52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99      1671\n",
      "           0       0.96      0.97      0.97      1722\n",
      "           1       0.92      0.90      0.91      1724\n",
      "           2       0.94      0.94      0.94      1707\n",
      "\n",
      "    accuracy                           0.95      6824\n",
      "   macro avg       0.95      0.95      0.95      6824\n",
      "weighted avg       0.95      0.95      0.95      6824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(X_train, y_train)\n",
    "model_Evaluate(SVCmodel)\n",
    "y_pred2 = SVCmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbbd5d",
   "metadata": {},
   "source": [
    "### Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "240a61dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98      1671\n",
      "           0       0.96      0.92      0.94      1722\n",
      "           1       0.86      0.89      0.87      1724\n",
      "           2       0.93      0.91      0.92      1707\n",
      "\n",
      "    accuracy                           0.93      6824\n",
      "   macro avg       0.93      0.93      0.93      6824\n",
      "weighted avg       0.93      0.93      0.93      6824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiating the model, training the model, calling the evaluation functon on the model and getting predictions from the model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "M_NB = MultinomialNB(alpha=0.1)\n",
    "M_NB.fit(X_train, y_train)\n",
    "model_Evaluate(M_NB)\n",
    "y_pred3= M_NB.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_submission(y_pred_value):\n",
    "    \n",
    "    tweetid = df_test['tweetid'] \n",
    "    my_dict = {'tweetid': tweetid,'sentiment':y_pred_value}\n",
    "    new_pandas = pd.DataFrame(my_dict)\n",
    "    return new_pandas.to_csv('file_13.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e27e41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "model_Evaluate(forest)\n",
    "y_pred4 = forest.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# tree = DecisionTreeClassifier(random_state=42)\n",
    "# tree.fit(X_train, y_train)\n",
    "# model_Evaluate(tree)\n",
    "# y_pred5 = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40115c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "292e6850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6824,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in 'C:\\\\Users\\\\hp 840\\\\Documents\\\\EXPLORE ACADEMY\\\\SPRINTS\\\\Advanced Classification\\\\Kaggle Competition' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/moreira/edsa-climate-change-belief-analysis-2022/7a76d030909f4b20920aa5388ca72ff0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"LOfWnyJWVQ0yynqkHLhoe1J2B\",\n",
    "    project_name=\"edsa-climate-change-belief-analysis-2022\",\n",
    "    workspace=\"moreira\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24f1d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving each metric to add to a dictionary for logging\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "precision = precision_score(y_test, y_pred, average = 'macro')\n",
    "recall = recall_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "faa48567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for the data we want to log\n",
    "\n",
    "# params = {\"random_state\": 7,\n",
    "#           \"model_type\": \"Linear\",\n",
    "#           \"scaler\": \"standard scaler\",\n",
    "#           \"param_grid\": str(param_grid),\n",
    "#           \"stratify\": True\n",
    "#           }\n",
    "metrics = {\"f1\": f1,\n",
    "           \"recall\": recall,\n",
    "           \"precision\": precision\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "14605520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log our parameters and results\n",
    "#experiment.log_parameters(params)\n",
    "experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9bfe1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/moreira/edsa-climate-change-belief-analysis-2022/7a76d030909f4b20920aa5388ca72ff0\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     f1        : 0.890906548581185\n",
      "COMET INFO:     precision : 0.8984401931861216\n",
      "COMET INFO:     recall    : 0.8889524439516074\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-environment-definition : 1\n",
      "COMET INFO:     conda-info                   : 1\n",
      "COMET INFO:     conda-specification          : 1\n",
      "COMET INFO:     environment details          : 1\n",
      "COMET INFO:     filename                     : 1\n",
      "COMET INFO:     installed packages           : 1\n",
      "COMET INFO:     notebook                     : 1\n",
      "COMET INFO:     source_code                  : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: Still uploading 2 file(s), remaining 52.85 KB/103.31 KB\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce90e78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"https://www.comet.ml/moreira/edsa-climate-change-belief-analysis-2022/7a76d030909f4b20920aa5388ca72ff0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x242408db820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
